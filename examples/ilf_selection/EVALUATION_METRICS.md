# ILF 功能点评估指标说明

本文档详细说明 ILF（内部逻辑文件）功能点识别结果的评估指标。

## 评估指标概览

在输出的 JSON 文件中，`evaluation_metrics` 字段包含以下评估指标：

```json
"evaluation_metrics": {
  "f1_score": 0.6,
  "precision": 0.9,
  "recall": 0.45,
  "exact_matches": 0,
  "fuzzy_score": 0.9,
  "semantic_matches": [
    "职位挂起文件 <-> Suspended job (0.90)"
  ]
}
```

## 各指标详细说明

### 1. F1 Score (f1_score)

**范围**: 0.0 ~ 1.0

**含义**: F1分数是精确率（Precision）和召回率（Recall）的调和平均数，综合反映模型识别ILF功能点的整体性能。

**计算公式**:
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)
```

**解释**:
- **1.0** = 完美识别，预测结果与真实答案完全一致
- **0.5 ~ 0.8** = 较好识别，大部分功能点被正确识别
- **< 0.5** = 识别效果一般，存在较多遗漏或误判
- **0.0** = 完全未识别到正确的功能点

**应用场景**: F1分数是评估整体性能的核心指标，尤其适用于需要平衡准确性和完整性的场景。

---

### 2. Precision (精确率)

**范围**: 0.0 ~ 1.0

**含义**: 在所有预测为ILF功能点的项中，有多少是真正正确的。反映模型识别的**准确性**。

**计算公式**:
```
Precision = (正确识别的功能点数) / (预测的功能点总数)
```

**示例**:
- 预测结果: `["职位挂起文件", "职位信息", "操作日志"]` (3个)
- 真实答案: `["Suspended job", "Suspended job description"]` (2个)
- 语义匹配: "职位挂起文件" ↔ "Suspended job" (0.90)
- 正确数: 0.90
- **Precision = 0.90 / 3 = 0.30**

**解释**:
- **高精确率** (>0.8): 预测的功能点大多是正确的，误报少
- **低精确率** (<0.5): 预测了很多不存在的功能点，误报多

---

### 3. Recall (召回率)

**范围**: 0.0 ~ 1.0

**含义**: 在所有真实的ILF功能点中，有多少被成功识别出来。反映模型识别的**完整性**。

**计算公式**:
```
Recall = (正确识别的功能点数) / (真实的功能点总数)
```

**示例**:
- 预测结果: `["职位挂起文件"]` (1个)
- 真实答案: `["Suspended job", "Suspended job description"]` (2个)
- 语义匹配: "职位挂起文件" ↔ "Suspended job" (0.90)
- 正确数: 0.90
- **Recall = 0.90 / 2 = 0.45**

**解释**:
- **高召回率** (>0.8): 几乎所有真实的功能点都被识别出来，遗漏少
- **低召回率** (<0.5): 遗漏了很多真实存在的功能点

---

### 4. Exact Matches (精确匹配数)

**范围**: 0 ~ N (整数)

**含义**: 预测结果与真实答案之间**完全相同**的功能点数量（不考虑大小写和空格）。

**匹配规则**:
- 名称标准化后完全一致
- 例如: `"User Information"` = `"user_information"` = `"USER INFORMATION"`

**示例**:
```json
预测: ["User Profile", "System Log"]
真实: ["User Profile", "Access Log"]
exact_matches: 1  // "User Profile" 完全匹配
```

**解释**:
- 反映模型在**名称规范性**上的表现
- 仅统计完全匹配，不包括语义相似的匹配

---

### 5. Fuzzy Score (模糊匹配总分)

**范围**: 0.0 ~ N (浮点数)

**含义**: 所有**非精确匹配**的功能点通过语义相似度判断后的累计得分。

**计算方式**:
1. 对于没有精确匹配的预测项，使用 LLM 判断其与真实答案的语义相似度
2. 相似度 > 0.7 的匹配被认为是有效匹配
3. 将所有有效匹配的相似度累加得到 fuzzy_score

**示例**:
```json
预测: ["职位挂起文件", "职位描述文件"]
真实: ["Suspended job", "Suspended job description"]

语义匹配:
- "职位挂起文件" ↔ "Suspended job": 0.90
- "职位描述文件" ↔ "Suspended job description": 0.85

fuzzy_score: 0.90 + 0.85 = 1.75
```

**解释**:
- **高模糊分数**: 虽然名称不完全一致，但语义上高度匹配
- 适用于**跨语言比较**（中英文）或**同义词识别**

---

### 6. Semantic Matches (语义匹配详情)

**类型**: 字符串数组

**含义**: 详细记录每一对通过语义相似度匹配的功能点及其相似度分数。

**格式**:
```
"预测的功能点名称 <-> 真实的功能点名称 (相似度分数)"
```

**示例**:
```json
"semantic_matches": [
  "职位挂起文件 <-> Suspended job (0.90)",
  "职位描述文件 <-> Suspended job description (0.85)",
  "操作日志 <-> System Log (0.75)"
]
```

**解释**:
- 提供**可追溯的匹配依据**，便于人工审核
- 相似度分数由 LLM 根据语义进行判断（范围 0.0 ~ 1.0）
- 只记录相似度 > 0.7 的匹配对

---

## 计算示例

### 示例 1: 部分识别（遗漏了功能点）

**场景**:
- 预测: `["职位挂起文件"]`
- 真实: `["Suspended job", "Suspended job description"]`

**匹配过程**:
1. 精确匹配: 0 个（中英文不同）
2. 语义匹配:
   - "职位挂起文件" vs "Suspended job": **0.90** ✓
   - "职位挂起文件" vs "Suspended job description": 0.40 ✗

**结果**:
```json
{
  "exact_matches": 0,
  "fuzzy_score": 0.90,
  "precision": 0.90 / 1 = 0.90,  // 预测1个，对了0.90
  "recall": 0.90 / 2 = 0.45,      // 真实2个，只找到0.90
  "f1_score": 2 × (0.90 × 0.45) / (0.90 + 0.45) = 0.60
}
```

**分析**: 精确率高（预测的基本都对），但召回率低（遗漏了一个功能点）。

---

### 示例 2: 过度识别（多预测了功能点）

**场景**:
- 预测: `["职位信息", "职位挂起文件", "操作日志"]`
- 真实: `["Suspended job", "Suspended job description"]`

**匹配过程**:
1. 精确匹配: 0 个
2. 语义匹配:
   - "职位信息" vs "Suspended job": **0.85** ✓
   - "职位挂起文件" vs "Suspended job description": **0.90** ✓
   - "操作日志": 无匹配 (< 0.7)

**结果**:
```json
{
  "exact_matches": 0,
  "fuzzy_score": 1.75,
  "precision": 1.75 / 3 = 0.58,   // 预测3个，对了1.75
  "recall": 1.75 / 2 = 0.88,      // 真实2个，找到了1.75
  "f1_score": 2 × (0.58 × 0.88) / (0.58 + 0.88) = 0.70
}
```

**分析**: 召回率高（找到了大部分功能点），但精确率低（多预测了无关项）。

---

### 示例 3: 完美识别

**场景**:
- 预测: `["Suspended job", "Suspended job description"]`
- 真实: `["Suspended job", "Suspended job description"]`

**结果**:
```json
{
  "exact_matches": 2,
  "fuzzy_score": 0.0,
  "precision": 1.0,
  "recall": 1.0,
  "f1_score": 1.0
}
```

---

## 指标应用建议

### 1. 模型优化方向

| 指标特征 | 问题诊断 | 优化建议 |
|---------|---------|---------|
| 高 Precision, 低 Recall | 模型过于保守，识别不完整 | 放宽判断条件，增加候选项 |
| 低 Precision, 高 Recall | 模型过于激进，误报太多 | 加强筛选逻辑，提高判断准确性 |
| Precision 和 Recall 都低 | 模型理解能力不足 | 改进 prompt 设计，增加示例 |

### 2. 阈值设置建议

```python
if f1_score >= 0.8:
    print("优秀：模型识别准确且完整")
elif f1_score >= 0.6:
    print("良好：模型基本能识别主要功能点")
elif f1_score >= 0.4:
    print("及格：模型有一定识别能力，但需改进")
else:
    print("不及格：模型识别能力不足")
```

### 3. 跨语言评估

系统支持**中英文混合评估**，通过 LLM 语义相似度判断实现智能匹配：
- 自动识别 "用户信息" ≈ "User Profile"
- 自动识别 "职位挂起文件" ≈ "Suspended job"

这使得即使预测和真实答案使用不同语言，也能获得准确的评估结果。

---

## 技术实现

### LLM 语义相似度判断

当 `use_lm_semantic=True` 时，系统会调用 LLM 判断两个功能点名称的语义相似度：

```python
# 示例 prompt
你是一个IFPUG功能点分析专家。请判断以下两个ILF功能点名称是否指代同一个功能点：
- 名称1：职位挂起文件
- 名称2：Suspended job

请考虑：
1. 语义是否等价（包括翻译、同义词）
2. 业务含义是否一致

输出 0.0-1.0 的相似度分数，格式：0.90
```

### 匹配流程

1. **第一步：精确匹配**
   - 标准化名称（小写、去除下划线和空格）
   - 比较是否完全相同
   - 统计 `exact_matches`

2. **第二步：语义匹配**
   - 对未匹配的项，使用 LLM 计算语义相似度
   - 相似度 > 0.7 的视为有效匹配
   - 累计得到 `fuzzy_score`

3. **第三步：计算综合指标**
   - 总匹配分 = exact_matches + fuzzy_score
   - Precision = 总匹配分 / 预测数
   - Recall = 总匹配分 / 真实数
   - F1 Score = 调和平均数

---

## 常见问题

### Q1: 为什么 F1 分数低于 Precision 和 Recall？
**A**: F1 是调和平均数，会更接近较小的那个值。这确保了只有当 Precision 和 Recall 都高时，F1 才高。

### Q2: fuzzy_score 可以超过 exact_matches 吗？
**A**: 可以。fuzzy_score 是累加的相似度分数，理论上可以达到任意大的值（取决于匹配数量）。

### Q3: 如果预测为空或真实答案为空怎么办？
**A**: 
- 两者都为空: F1 = 1.0（完全匹配）
- 一方为空: F1 = 0.0（完全不匹配）

### Q4: 语义匹配的阈值为什么是 0.7？
**A**: 0.7 是经验值，平衡了召回率和准确率。可以根据实际需求调整：
- 提高阈值（如 0.8）: 更严格，减少误判
- 降低阈值（如 0.6）: 更宽松，减少遗漏

---

## 参考资料

- [IFPUG 功能点分析手册](https://www.ifpug.org/)
- [F1 Score 详解](https://en.wikipedia.org/wiki/F-score)
- 项目代码: `examples/ilf_selection/ilf_selection.py` (第115-220行)

