## 5.5.2 模型差异：规模效应与基座偏置 (Model Discrepancies: Scaling Laws and Foundation Bias)

本实验跨越了从 7B 到 671B 参数规模的多个模型，其结果不仅验证了经典的 Scaling Law 在逻辑推理任务中的适用性，更揭示了不同规模模型在面对复杂规则时截然不同的失效模式（Failure Modes）与潜能边界。

对于参数受限的小型模型（如 r1-7b），实验数据展现了一种显著的“能力涌现门槛”现象，以及 GoT 架构所带来的“辅助轮效应”。在 ILF 识别任务中，r1-7b 在 IO 范式下的 F1 分数仅为 17.6%，几乎等同于随机生成的噪音。然而，一旦接入 GoT 架构，其性能跃升至 69.0%，实现了质的突破。这一反直觉的现象表明，小模型并非完全缺乏理解业务规则的能力，而是缺乏在长上下文中自主规划推理路径的内在深度。GoT 通过外部注入显式的分解-验证结构，有效地“外挂”了原本只有大模型才具备的规划能力，使得小模型能够跨越认知门槛，由不可用变为可用。然而，这种增强并非无限的。在逻辑更复杂的 EIF 判别任务中，过于复杂的图谱结构反而导致 r1-7b 的表现落后于计算量较小的 ToT。这暗示了“推理过载”的存在：当外部注入的提示词结构复杂度超过了小模型有限的注意力窗口与指令遵循能力时，结构本身反而成为了认知负担。

相反，在超大规模模型组（Qwen3-235B 与 DeepSeek-V3-671B）身上，我们观察到了有趣的性能分化，这揭示了“基座偏置”的双刃剑效应。尽管拥有 235B 的参数量，Qwen3-235B 在 ILF 判别任务中表现出了强烈的过度自信，倾向于将所有候选实体判定为合规（IO/CoT 模式下 TN=0）。即使引入 GoT 架构，其 F1 分数改善也相对有限。这提示我们，200B 级别的模型虽然具备了强大的语义理解力，但可能在预训练阶段“记忆”了过多的正样本模式，导致难以通过简单的 Prompt 纠正其先验假设。

与此形成鲜明对比的是，本实验中参数量最大的模型 DeepSeek-V3 (671B MoE) 展现了真正“专家级”的判别力。它不仅在 GoT 架构下实现了 100% 的准确率，更重要的是，即便在 IO 范式下，它也能较好地平衡精确率与召回率。这表明，当模型规模进一步扩展至 600B+ 级别时，模型似乎“涌现”出了更强的逻辑中立性，能够更好地抑制预训练语料中的分布偏见，精确遵循当前指令中的复杂否定约束。

综上所述，模型规模与推理效能之间并非简单的线性关系。小模型需要“强结构”来弥补深度的不足，但需警惕上下文过载；中大模型（200B+）可能面临“自信过头”的挑战；而超大模型（600B+）则显示出了返璞归真的逻辑鲁棒性。未来的自动化 FPA 系统设计，应当根据基座模型的特性动态调整 GoT 的拓扑复杂度与提示策略，以实现最优的人机协同效能。
