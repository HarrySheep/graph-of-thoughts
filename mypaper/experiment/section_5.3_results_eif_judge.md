## 5.3 EIF 评审实验结果 (Results on EIF Judgment Tasks)

本节报告了大型语言模型在外部接口文件（EIF）判别任务上的实验结果。EIF 判别任务的核心在于验证候选实体是否在当前边界之外但在其他应用边界之内，并且不仅是被引用（Referenced）而非维护。相比 ILF，EIF 的判定逻辑涉及跨边界的依赖关系，对模型的上下文理解能力提出了更高要求。

### 5.3.1 实验结果汇总 (Summary of Experimental Results)

表 5-3 展示了 DeepSeek-V3, Qwen3 系列及 r1-7b 模型在四种推理范式下对 EIF 判别的详细性能指标。

| 模型方案 | TP | TN | FP | FN | Accuracy | Precision | Recall | F1 Score | 推理成本 (Avg) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **DeepSeek-V3** | | | | | | | | | |
| └─ IO | 1 | 7 | 0 | 2 | 80.0% | 100.0% | 33.3% | 50.0% | $0.0013 |
| └─ CoT | 3 | 5 | 2 | 0 | 80.0% | 60.0% | 100.0% | 75.0% | $0.0012 |
| └─ ToT | 3 | 5 | 2 | 0 | 80.0% | 60.0% | 100.0% | 75.0% | $0.0064 |
| └─ **GoT (Ours)** | **3** | **7** | **0** | **0** | **100.0%** | **100.0%** | **100.0%** | **100.0%** | **$0.0135** |
| **Qwen3-235B** | | | | | | | | | |
| └─ IO | 2 | 6 | 1 | 1 | 80.0% | 66.7% | 66.7% | 66.7% | $0.0041 |
| └─ CoT | 3 | 5 | 2 | 0 | 80.0% | 60.0% | 100.0% | 75.0% | $0.0051 |
| └─ ToT | 3 | 3 | 4 | 0 | 60.0% | 42.9% | 100.0% | 60.0% | $0.0211 |
| └─ **GoT (Ours)** | **3** | **7** | **0** | **0** | **100.0%** | **100.0%** | **100.0%** | **100.0%** | **$0.0559** |
| **Qwen3-30B** | | | | | | | | | |
| └─ IO | 2 | 5 | 2 | 1 | 70.0% | 50.0% | 66.7% | 57.1% | $0.0016 |
| └─ CoT | 3 | 3 | 4 | 0 | 60.0% | 42.9% | 100.0% | 60.0% | $0.0024 |
| └─ ToT | 2 | 5 | 2 | 1 | 70.0% | 50.0% | 66.7% | 57.1% | $0.0087 |
| └─ **GoT (Ours)** | **2** | **7** | **0** | **1** | **90.0%** | **100.0%** | **66.7%** | **80.0%** | **$0.0240** |
| **r1-7b** | | | | | | | | | |
| └─ IO | 3 | 0 | 7 | 0 | 30.0% | 30.0% | 100.0% | 46.2% | $0.0013 |
| └─ CoT | 2 | 3 | 4 | 1 | 50.0% | 33.3% | 66.7% | 44.4% | $0.0016 |
| └─ ToT | 3 | 4 | 3 | 0 | 70.0% | 50.0% | 100.0% | 66.7% | $0.0055 |
| └─ **GoT (Ours)** | **3** | **3** | **4** | **0** | **60.0%** | **42.9%** | **100.0%** | **60.0%** | **$0.0186** |

### 5.3.2 结果分析 (Results Analysis)

根据表 5-3 的实验数据，各模型在 EIF 判别任务上的表现如下：

1.  **DeepSeek-V3 与 Qwen3-235B 的表现**：
    在这两个超大参数规模模型上，GoT 范式均取得了 100.0% 的准确率和 F1 分数。与同组的 IO、CoT、ToT 范式（准确率普遍在 80% 或更低）相比，GoT 成功消除了假阳性（FP=0）和假阴性（FN=0），实现了对测试样本的完全正确判别。

2.  **Qwen3-30B 的表现**：
    在 Qwen3-30B 模型上，GoT 范式将准确率从 CoT 的 60.0% 提升至 90.0%，F1 分数达到 80.0%。这是该模型组别下的最优成绩，显著优于 ToT (57.1%) 和 IO (57.1%)。

3.  **r1-7b 的表现**：
    对于 r1-7b 模型，不同推理范式的表现呈现波动。ToT 范式取得了该组最高的 70.0% 准确率。GoT 范式虽然较 IO (30.0%) 和 CoT (50.0%) 有所提升，达到 60.0% 的准确率，但未超过 ToT 的表现。

4.  **推理成本数据**：
    在达到 100% 准确率的 DeepSeek-V3 组别中，GoT 的平均推理成本 ($0.0135) 约为 IO ($0.0013) 的 10 倍。在 Qwen3-235B 上，这一倍率约为 13 倍 ($0.0559 vs $0.0041)。
