## 4.2 评估指标 (Evaluation Metrics)

在功能点分析（FPA）的自动化评估中，评估指标的设计必须兼顾规则执行的严谨性与自然语言表达的灵活性。针对本研究涉及的判别任务（Judgment Tasks）与识别任务（Selection Tasks），我们构建了一个多维度的评估框架。该框架不仅采用经典的机器学习性能指标来衡量模型对 IFPUG 准则的判别一致性，还引入了一种创新的语义感知匹配机制，以解决软件需求描述中广泛存在的词汇异构与语义重合问题。

### 4.2.1 判别任务的可靠性度量 (Metrics for Judgment Tasks)

判别任务本质上是检验大型语言模型（LLM）作为“合规性审计员”的能力，即判定给定的候选实体是否完全契合功能点计数手册（CPM）中关于内部逻辑文件（ILF）或外部接口文件（EIF）的定义。此类任务被建模为二分类问题（True/False），其评估重点在于模型决策的一致性与严谨性。我们通过以下四个维度来度量模型的可靠性：

1.  **准确率 (Accuracy)**：
    反映模型在全体判别样本上的整体表现。高准确率意味着模型在区分“合规实体”与“干扰项”时具备扎实的基础判别能力。
    $$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$

2.  **精确率 (Precision)**：
    语义重点在于**“评估的可信度”**。在 FPA 实践中，精确率的高低直接关联到“功能点冒领”导致成本虚高的风险（Over-counting）。高精确率能确保模型识别出的每一个功能点都经得起 CPM 规则的推敲。
    $$ Precision = \frac{TP}{TP + FP} $$

3.  **召回率 (Recall)**：
    语义重点在于**“评估的完备性”**。召回率不足意味着存在“缺失功能”或“影子文件”（Under-counting），这会导致开发成本与进度的严重低估。高召回率是确保系统核心逻辑资产不被遗漏的关键指标。
    $$ Recall = \frac{TP}{TP + FN} $$

4.  **F1 分数 (F1 Score)**：
    作为精确率与召回率的调和平均数，F1 分数代表了模型在处理复杂边界案例时的**“综合博弈水平”**。由于功能点分析数据集往往存在正负样本不平衡（干扰实体通常多于真实逻辑文件），F1 分数能比单纯的准确率更客观地揭示模型的稳健性。
    $$ F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} $$


### 4.2.2 识别任务的语义感知匹配体系 (Metrics for Selection Tasks)

与判别任务不同，识别任务属于复杂的信息抽取（Information Extraction）范畴，要求模型从非结构化的自然语言需求中提取出所有的逻辑实体。由于不同分析师或需求编写者对同一业务概念的表述往往存在显著差异（例如，同一员工档案可能被描述为 "EMPLOYEE_MASTER"、"员工信息表" 或 "Personal Profile"），传统的精确字符串匹配（Lexical Match）会导致大量语义正确但表述不一的结果被误判为错误。

为克服这一局限性，本研究构建了基于大语言模型评分器（LLM Scorer）的语义感知评估体系。该体系通过计算预测实体 $p$ 与真值实体 $t$ 之间的语义相似度 $Sim(p, t)$，并设置阈值 $\tau = 0.7$ 来判定匹配的有效性。具体指标定义如下：

1.  **exact_matches (精确匹配数)**：记录预测结果中与真值完全一致的实体数量。该指标代表了模型输出的规范性，即模型在多大程度上能够复现行业标准的术语表达。

2.  **fuzzy_score (模糊匹配总分)**：作为评估体系的核心，该指标被定义为所有有效语义匹配对的相似度累加值，即 $TP_{fuzzy} = \sum Sim(p, t)$。与简单计数相比，`fuzzy_score` 将模型对业务逻辑的理解深度转化为连续的分值，能够更公平地评价那些“虽不中亦不远”的识别结果。

3.  **semantic_matches (语义匹配记录)**：该指标以列表形式记录了所有通过相似度校验的配对细节（如 `"EMPLOYEE_MASTER <-> Employee information (HR Application) (0.95)"`）。这不仅增强了实验结果的可解释性，也为后续的错误根因分析提供了定性的专家反馈。

4.  **基于语义的宏观综合指标 (Macro Semantic Performance Metrics)**：
    为了在信息检索（Information Retrieval）的框架下量化抽取效能，我们将精确匹配与语义匹配的贡献统一为**有效真阳性总数 (Total Effective Matches, $M_{total}$)**：
    $$ M_{total} = exact\_matches + fuzzy\_score $$
    以此为基础，结合预测实体总数 $|Pred|$ 与真实实体总数 $|Truth|$，推导出了以下三项核心宏观指标：

    *   **语义感知精确率 (Precision)**：
        反映模型预测结果中有效信息的比例。在 FPA 自动化工具中，该指标越高，说明生成的实体列表中业务相关的“纯度”越高。
        $$ precision = \frac{M_{total}}{|Pred|} $$

    *   **语义感知召回率 (Recall)**：
        反映模型对业务需求中核心逻辑实体的覆盖程度。由于得分中包含了 `fuzzy_score`，该指标能够客观地评价模型在术语表述不一致时，是否依然捕获到了用户意图。
        $$ recall = \frac{M_{total}}{|Truth|} $$

    *   **语义感知 F1 分数 (F1 Score)**：
        作为精确率与召回率的平滑权衡，F1 分数代表了模型在**“提取广度”与“语义精度”之间的综合效能**。在功能点分析的实战测试中，它是衡量方案优劣的最核心指标。
        $$ f1\_score = 2 \cdot \frac{precision \cdot recall}{precision + recall} $$



通过引入这套语义感知匹配体系，评价过程从机械的字面校验升华为深层的意图对齐，从而能够更真实地反映模型在真实企业级复杂需求文档中识别核心逻辑文件的实战能力。
