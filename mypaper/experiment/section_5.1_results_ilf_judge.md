## 5.1 ILF 评审实验结果 (Results on ILF Judgment Tasks)

本节报告了大型语言模型在内部逻辑文件（ILF）判别任务上的实验结果。该任务旨在评估模型依据 IFPUG 规则手册，对候选逻辑实体进行二分类判别（合规/不合规）的能力。我们对比了 IO (Direct Input-Output), CoT (Chain-of-Thoughts), ToT (Tree-of-Thoughts) 以及本研究提出的 GoT (Graph-of-Thoughts) 四种推理范式。

### 5.1.1 实验结果汇总 (Summary of Experimental Results)

表 5-1 展示了各模型在不同推理范式下的详细性能指标，包括混淆矩阵 (TP, TN, FP, FN)、准确率 (Accuracy)、精确率 (Precision)、召回率 (Recall)、F1 分数以及平均推理成本。

| 模型方案 | TP | TN | FP | FN | Accuracy | Precision | Recall | F1 Score | 推理成本 (Avg) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **DeepSeek-V3** | | | | | | | | | |
| └─ IO | 5 | 3 | 2 | 0 | 80.0% | 71.4% | 100.0% | 83.3% | $0.0039 |
| └─ CoT | 5 | 2 | 3 | 0 | 70.0% | 62.5% | 100.0% | 76.9% | $0.0041 |
| └─ ToT | 5 | 4 | 1 | 0 | 90.0% | 83.3% | 100.0% | 90.9% | $0.0782 |
| └─ **GoT (Ours)** | **5** | **4** | **1** | **0** | **90.0%** | **83.3%** | **100.0%** | **90.9%** | **$0.0792** |
| **Qwen3-235B** | | | | | | | | | |
| └─ IO | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.0212 |
| └─ CoT | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.0250 |
| └─ ToT | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.1039 |
| └─ **GoT (Ours)** | **3** | **2** | **3** | **2** | **50.0%** | **50.0%** | **60.0%** | **54.5%** | **$0.2618** |
| **Qwen3-30B** | | | | | | | | | |
| └─ IO | 4 | 1 | 4 | 1 | 50.0% | 50.0% | 80.0% | 61.5% | $0.0223 |
| └─ CoT | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.0264 |
| └─ ToT | 4 | 0 | 5 | 1 | 40.0% | 44.4% | 80.0% | 57.1% | $0.1043 |
| └─ **GoT (Ours)** | **4** | **3** | **2** | **1** | **70.0%** | **66.7%** | **80.0%** | **72.7%** | **$0.3036** |
| **r1-7b** | | | | | | | | | |
| └─ IO | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.0193 |
| └─ CoT | 5 | 0 | 5 | 0 | 50.0% | 50.0% | 100.0% | 66.7% | $0.0217 |
| └─ ToT | 4 | 0 | 5 | 1 | 40.0% | 44.4% | 80.0% | 57.1% | $0.0759 |
| └─ **GoT (Ours)** | **5** | **3** | **2** | **0** | **80.0%** | **71.4%** | **100.0%** | **83.3%** | **$0.2346** |

### 5.1.2 结果分析 (Results Analysis)

根据表 5-1 的实验数据，各模型在 ILF 判别任务上的表现如下：

1.  **DeepSeek-V3 的表现**：
    在 DeepSeek-V3 模型上，GoT 与 ToT 范式均取得了最高的 90.0% 准确率和 90.9% 的 F1 分数。相比于 IO 和 CoT 范式（准确率分别为 80.0% 和 70.0%），结构化推理显著降低了误报数（FP 从 2-3 降至 1），提升了精确率。

2.  **Qwen3-235B 的表现**：
    Qwen3-235B 在 IO、CoT 和 ToT 范式下均表现出完全的“正向预测倾向”，即预测所有样本为真（TP=5, TN=0），导致准确率停留在 50.0%。引入 GoT 后，模型开始尝试区分负样本（TN=2），但同时也损失了部分召回率（FN增加），整体 F1 分数下降至 54.5%。

3.  **Qwen3-30B 的表现**：
    Qwen3-30B 在 GoT 范式下取得了该模型组最佳的综合性能，准确率达到 70.0%，F1 分数为 72.7%。相较于其他三种范式（准确率 40%-50%），GoT 有效平衡了精确率（66.7%）和召回率（80.0%）。

4.  **r1-7b 的表现**：
    在参数量最小的 r1-7b 模型上，GoT 范式带来的性能提升最为明显。其准确率从 IO/CoT 的 50.0%（相当于随机猜测）提升至 80.0%，F1 分数达到 83.3%，在数值上接近 DeepSeek-V3 的基准表现。
