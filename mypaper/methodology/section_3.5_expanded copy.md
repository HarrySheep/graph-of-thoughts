## 3.5 评估指标与语义匹配 (Evaluation Metrics & Semantic Matching)

为了全面且客观地量化各方法在功能点识别任务中的效能，我们构建了一套融合传统信息检索指标与领域自适应语义匹配的混合评估体系。该体系不仅关注识别结果的统计学准确性，更通过引入大语言模型作为裁判，解决了功能点分析中长期存在的命名多样性与跨语言对齐难题。

### 3.5.1 基础效能指标 (Fundamental Performance Metrics)

我们采用信息检索（Information Retrieval）领域的三个核心指标来衡量模型的有效性：精确率（Precision）、召回率（Recall）和 F1 分数（F1 Score）。

*   **精确率 (Precision)** 反映了模型输出结果的纯净度，即在模型识别出的所有功能点候选项中，经人工或标准答案验证为正确的比例。高精确率意味着模型具有较低的误报率（False Positive Rate），能够有效抑制系统幻觉。
*   **召回率 (Recall)** 衡量了模型对真实需求的覆盖程度，即所有标准答案中的功能点被模型成功捕获的比例。在功能点分析场景下，高召回率至关重要，因为遗漏任何关键数据实体都可能导致项目规模估算的显著偏差。
*   **F1 分数 (F1 Score)** 作为精确率与召回率的调和平均数，是我们评价模型综合性能的首要指标。考虑到功能点估算既要求不重（准确）也不漏（完整），F1 分数能最公正地反映模型在权衡两者时的稳健性。

### 3.5.2 基于 LLM 的语义一致性校验 (LLM-based Semantic Alignment)

在传统的自动化软件工程任务中，评估往往依赖于严格的字符串匹配（String Exact Match）。然而，在 IFPUG 功能点识别中，这种刚性匹配面临巨大挑战。同一功能实体往往存在多义性表达，例如标准答案中的 "Employee Security" 在实际需求文档或模型输出中可能被表述为 "人员访问控制文件" 或 "User Permission Config"。

为了突破硬编码映射（Hard-coded Mapping）的局限性，我们设计并实现了一种基于 LLM 的**语义相似度评分机制 (Semantic Similarity Scoring)**。该机制将评估过程从“通过/失败”的二元判定提升为连续的语义距离度量，具体流程如下：

首先，系统执行**标准化预处理**，对模型输出与真实基准（Ground Truth）进行去噪、归一化处理，并优先筛选出完全一致的精确匹配项（Exact Matches）。

其次，针对未能精确命中的剩余项，系统激活**语义裁判代理**。该代理通过特定的 Prompt 引导 LLM 进入“IFPUG 专家仲裁”模式，综合考虑中英文翻译差异、领域术语缩写以及描述性同义词等因素，计算候选词与基准词之间的语义相似度概率 $P_{sim} \in [0, 1]$。

最后，我们引入**模糊匹配累计分 (Fuzzy Score)** 概念。仅当 $P_{sim}$ 超过置信度阈值 $\tau$（本实验设定 $\tau=0.7$）时，该匹配才被认定为有效，并将其相似度分值计入最终的统计。这种混合评分策略不仅展现了比 Levenshtein 距离等传统算法更高的鲁棒性，还有效解决了跨语言环境下的自动化评估难题，确保了实验结果能够真实反映模型对业务逻辑的理解深度，而非仅仅是对特定词汇的记忆能力。

通过 F1 分数与语义匹配机制的结合，我们建立了一个既严谨又具适应性的评估框架，为后续对比 GoT 与基准方法提供了坚实的数据支撑。
