## 3.2 对比基准方法实现 (Implementation of Baseline Methods)

为了全方位评估 GoT 框架在功能点评估任务中的性能表现，我们建立了一个包含三种不同推理范式的基准测试组。这些基准方法分别代表了当前大语言模型在零样本推理、线性推理和迭代推理三个层级的能力特征。我们在实验中严格控制了模型参数与环境配置，确保对比的公平性。

### 3.2.1 Input-Output (IO) 标准提示
IO 方法是最基础的零样本（Zero-Shot）推理模式。在此模式下，我们不仅不提供任何少样本（Few-Shot）示例，也不通过 Prompt 引导模型展示中间推理步骤。该方法主要用于评估 LLM 仅凭预训练知识对 IFPUG 规则的内化程度和直接应用能力。

*   **实现逻辑**：
    我们将需求文档作为上下文直接输入模型，并要求其仅输出最终的功能点列表。这种“黑盒”式的处理方式模拟了普通用户在不做任何 Prompt Engineering 时的使用场景。

*   **流程图**：
    ```mermaid
    graph LR
        Input[需求文档] -- Direct Prompting --> LLM[大语言模型]
        LLM --> Output[功能点列表]
        style Input fill:#f9f,stroke:#333,stroke-width:2px
        style Output fill:#9f9,stroke:#333,stroke-width:2px
    ```

*   **Prompt 结构示例**：
    ```text
    你是一个IFPUG功能点分析专家。请分析给定的需求文档，识别出其中所有可能的ILF/EIF功能点。
    [需求文档内容]
    **【重要】请严格按照以下格式输出：**
    功能点列表：[功能点1, 功能点2]
    ```

*   **预期局限**：由于缺乏“思考时间”（中间 Token 的生成过程），模型往往难以捕捉隐晦的需求细节，极易产生遗漏或因联想而产生“幻觉”（Hallucination）。

### 3.2.2 Chain of Thought (CoT) 思维链
CoT 方法利用了 LLM 的“思维链”能力，通过显式要求模型输出推导过程，将复杂的判断任务分解为一系列线性步骤。在功能点识别场景中，我们将专家思维内化为 Prompt 中的具体指令序列。

*   **实现逻辑**：
    我们将推理过程拆解为“实体识别 $\rightarrow$ 属性验证 $\rightarrow$ 结论判定”的流水线。模型必须先列出所有潜在的数据实体，再逐一验证其是否满足逻辑独立性、边界外存储等关键条件，最后才生成结果列表。

*   **流程图**：
    ```mermaid
    graph TD
        Start[需求文档] --> Step1[步骤1: 识别外部数据源/实体]
        Step1 --> Step2[步骤2: 验证逻辑独立性]
        Step2 --> Step3[步骤3: 验证维护边界与操作]
        Step3 --> Step4[步骤4: 过滤不合规项]
        Step4 --> End[最终功能点列表]
    ```

*   **Prompt 设计策略**：
    > “请按照以下步骤进行分析：
    > 1. 识别需求文档中提到的所有外部数据源/接口。
    > 2. 对每个外部数据源，判断是否逻辑上独立且用户可识别。
    > 3. 判断是否不由当前应用进行维护（即只读）。
    > 4. 根据以上分析，列出所有满足条件的功能点。”

*   **优势与不足**：CoT 显著降低了逻辑跳跃带来的错误，提升了结果的可解释性。然而，其根本缺陷在于**单向不可逆性**：一旦在 Step 1 遗漏了某个实体，或在 Step 2 做出了错误判断，后续步骤无法感知错误并进行自我纠正（Error Propagation）。

### 3.2.3 Tree of Thoughts (ToT) 思维树
ToT 方法引入了更高级的“生成-评估-搜索”机制。不同于 CoT 的单次通过，ToT 允许模型生成多个思维路径，或对单一路径进行多轮自我反思与修正。在我们的实验实现中，采用了 **“生成 $\rightarrow$ 评分 $\rightarrow$ 优选 $\rightarrow$ 改进”** 的线性迭代变体。

*   **实现逻辑**：
    模型首先生成一个初始的功能点列表，随后进入迭代循环：
    1.  **Generate**：基于当前结果尝试生成更好的方案。
    2.  **Score**：自我评估当前方案的完整性与准确性。
    3.  **KeepBest**：保留得分最高的方案作为下一轮的基础。
    4.  **Improve**：针对当前方案的弱点（如遗漏、误判）进行针对性修正。

*   **流程图**：
    ```mermaid
    graph TD
        Start[输入需求] --> Gen1[初步生成]
        Gen1 --> Eval1{自我评分}
        Eval1 -- 分数低 --> Refine[反思与改进]
        Refine --> Gen2[生成改进方案]
        Gen2 --> Eval2{再次评分}
        Eval2 -- 达标/迭代结束 --> Final[最终结果]
        Eval1 -- 分数高 --> Final
    ```

*   **Prompt 示例**：
    > “基于之前的分析结果进行改进：
    > 之前识别的功能点：{current_answer}
    > 请检查是否有遗漏的 EIF 功能点，或者是否有误判的非 EIF 功能点（例如内部数据）。重新验证三要素，并给出改进后的列表。”

*   **特点分析**：ToT 具备了一定的自我纠错能力，能够通过多轮迭代优化结果。然而，它仍然容易陷入**单一维度的思维定势**（例如一直忽略某个特定的需求盲点），缺乏不同视角（如业务 vs 技术）之间的交叉验证机制。这正是 GoT 框架试图解决的核心问题。
